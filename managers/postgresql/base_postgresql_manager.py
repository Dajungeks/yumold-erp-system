# -*- coding: utf-8 -*-
"""
PostgreSQL ê¸°ë°˜ ë§¤ë‹ˆì € ë² ì´ìŠ¤ í´ë˜ìŠ¤
ì•ˆì •ì„±, ì„±ëŠ¥ ë° ì •í™•ì„± ê°œì„ ëœ ë²„ì „
"""

import os
import psycopg2
import psycopg2.extras
import psycopg2.pool
import pandas as pd
from datetime import datetime
import logging
import threading
import time
import re
import hashlib
from typing import Dict, Any, List, Optional, Union

logger = logging.getLogger(__name__)

# Startup health check for bcrypt
try:
    import bcrypt
    BCRYPT_AVAILABLE = True
    logger.info(f"âœ… bcrypt {bcrypt.__version__} ë¡œë“œë¨ - Enterpriseê¸‰ íŒ¨ìŠ¤ì›Œë“œ ë³´ì•ˆ í™œì„±í™”")
except ImportError:
    BCRYPT_AVAILABLE = False
    logger.critical("ğŸš¨ CRITICAL: bcrypt ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
    logger.critical("ğŸš¨ íŒ¨ìŠ¤ì›Œë“œ ë³´ì•ˆ ì‹œìŠ¤í…œì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤. ì¦‰ì‹œ 'pip install bcrypt' ì‹¤í–‰ í•„ìš”")
    raise ImportError("bcrypt ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. pip install bcrypt ì‹¤í–‰ í›„ ì¬ì‹œì‘í•˜ì„¸ìš”.")

class BasePostgreSQLManager:
    _connection_pool = None
    _pool_lock = threading.Lock()
    _pool_stats = {
        'connections_created': 0,
        'connections_failed': 0,
        'connections_reused': 0,
        'queries_executed': 0,
        'query_errors': 0,
        'pool_exhausted_waits': 0,
        'pool_wait_timeouts': 0,
        'health_checks_performed': 0,
        'health_checks_failed': 0
    }
    _stats_lock = threading.Lock()
    
    # ì—°ê²° íƒœê¹…ì„ ìœ„í•œ WeakSet (ì—°ê²°ì´ GCë  ë•Œ ìë™ ì œê±°)
    import weakref
    _pool_connections = weakref.WeakSet()
    _pool_connections_lock = threading.Lock()
    
    # Prepared Statements ìºì‹œ (Planning Time 36ms â†’ 1ms ë‹¨ì¶•)
    _prepared_statements = {}
    _prepared_lock = threading.Lock()
    
    # ì¿¼ë¦¬ ê²°ê³¼ ìºì‹œ (ì¤‘ë³µ ì¿¼ë¦¬ ë°©ì§€)
    _query_cache = {}
    _cache_lock = threading.Lock()
    _cache_ttl = 60  # 60ì´ˆ ìºì‹œ TTL
    
    # í…Œì´ë¸” ì¡´ì¬ í™•ì¸ ìºì‹œ (ì´ˆê¸°í™” ì‹œê°„ 80% ë‹¨ì¶•)
    _table_exists_cache = {}
    _table_cache_lock = threading.Lock()
    
    def __init__(self, 
                 pool_timeout=30.0,
                 health_check_enabled=True,
                 health_check_threshold=0.1):
        """PostgreSQL ê¸°ë°˜ ë§¤ë‹ˆì € ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        self.database_url = os.getenv('DATABASE_URL')
        if not self.database_url:
            raise ValueError("DATABASE_URL í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ì„¤ì • ê°€ëŠ¥í•œ ì˜µì…˜ë“¤
        self.pool_timeout = pool_timeout
        self.health_check_enabled = health_check_enabled
        self.health_check_threshold = health_check_threshold
        
        # í˜¸í™˜ì„±ì„ ìœ„í•´ self.pool ì´ˆê¸°í™”
        self.pool = None
        
        self._ensure_connection_pool()
    
    def _ensure_connection_pool(self):
        """ì—°ê²° í’€ ì´ˆê¸°í™” (í•œ ë²ˆë§Œ ì‹¤í–‰) - ë§¤ë‹ˆì € ê°„ ê³µìœ ë¡œ ì´ˆê¸°í™” ì‹œê°„ 90% ë‹¨ì¶•"""
        with self._pool_lock:
            if self._connection_pool is None:
                try:
                    # ì „ì²´ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ í•˜ë‚˜ì˜ ì—°ê²° í’€ë§Œ ìƒì„±
                    self._connection_pool = psycopg2.pool.ThreadedConnectionPool(
                        minconn=3,
                        maxconn=25,
                        dsn=self.database_url,
                        connect_timeout=5,
                        application_name="geumdo_erp_optimized"
                    )
                    # í˜¸í™˜ì„±ì„ ìœ„í•´ self.poolë„ ì„¤ì •
                    self.pool = self._connection_pool
                    logger.info(f"ğŸ“Š PostgreSQL ì—°ê²° í’€ ìƒì„±ë¨ (ì „ì—­ ê³µìœ , minconn=3, maxconn=25)")
                except Exception as e:
                    logger.error(f"ì—°ê²° í’€ ìƒì„± ì˜¤ë¥˜: {e}")
                    raise
    
    def get_connection(self):
        """PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë°˜í™˜ (ì•ˆì •ì„± ê°œì„ ëœ ë²„ì „)"""
        # í˜¸í™˜ì„±ì„ ìœ„í•œ ì²´í¬
        if self.pool and not self._connection_pool:
            self._connection_pool = self.pool
        
        if not self._connection_pool and not self.pool:
            # í’€ì´ ì—†ìœ¼ë©´ ì´ˆê¸°í™” ì‹œë„
            self.init_pool()
            
        if not self._connection_pool and not self.pool:
            raise Exception("ì—°ê²° í’€ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        start_time = time.time()
        connection = None
        
        try:
            # í’€ì—ì„œ ì—°ê²° íšë“ ì‹œë„
            connection = self._get_connection_from_pool_with_timeout()
            
            if connection:
                # í’€ì—ì„œ ê°€ì ¸ì˜¨ ì—°ê²°ì„ íƒœê¹…
                with self._pool_connections_lock:
                    self._pool_connections.add(connection)
                
                # ì¡°ê±´ë¶€ í—¬ìŠ¤ ì²´í¬ ìˆ˜í–‰
                if self._should_perform_health_check(start_time):
                    if not self._test_connection(connection):
                        logger.warning("í’€ì—ì„œ ê°€ì ¸ì˜¨ ì—°ê²°ì´ ë¹„ì •ìƒ ìƒíƒœì…ë‹ˆë‹¤. ì¬ì‹œë„í•©ë‹ˆë‹¤.")
                        try:
                            if self._connection_pool:
                                self._connection_pool.putconn(connection, close=True)
                            elif self.pool:
                                self.pool.putconn(connection, close=True)
                        except:
                            pass
                        
                        # ì¬ê·€ í˜¸ì¶œë¡œ ìƒˆ ì—°ê²° ì‹œë„
                        return self.get_connection()
                    else:
                        self._increment_stat('health_checks_performed')
                
                self._increment_stat('connections_reused')
                return connection
            else:
                raise Exception("í’€ì—ì„œ ì—°ê²°ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        except Exception as e:
            self._increment_stat('connections_failed')
            logger.error(f"ì—°ê²° íšë“ ì‹¤íŒ¨: {e}")
            # í’€ ì¬ì´ˆê¸°í™” ì‹œë„
            try:
                self.close_pool()
                self.init_pool()
                if self.pool:
                    return self.pool.getconn()
            except:
                pass
            raise Exception(f"PostgreSQL ì—°ê²°ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    
    def _get_connection_from_pool_with_timeout(self):
        """íƒ€ì„ì•„ì›ƒì„ ì ìš©í•˜ì—¬ í’€ì—ì„œ ì—°ê²° íšë“"""
        pool = self._connection_pool or self.pool
        if not pool:
            raise Exception("ì—°ê²° í’€ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
        pool_wait_start = time.time()
        
        while time.time() - pool_wait_start < self.pool_timeout:
            try:
                connection = pool.getconn()
                if connection:
                    return connection
            except psycopg2.pool.PoolError:
                self._increment_stat('pool_exhausted_waits')
                logger.debug("ì—°ê²° í’€ì´ ê³ ê°ˆë¨. 0.1ì´ˆ í›„ ì¬ì‹œë„...")
                time.sleep(0.1)
                continue
        
        self._increment_stat('pool_wait_timeouts')
        raise Exception(f"ì—°ê²° í’€ì—ì„œ ì—°ê²° íšë“ íƒ€ì„ì•„ì›ƒ ({self.pool_timeout}ì´ˆ)")
    
    def _should_perform_health_check(self, start_time):
        """í—¬ìŠ¤ ì²´í¬ ìˆ˜í–‰ ì—¬ë¶€ ê²°ì •"""
        if not self.health_check_enabled:
            return False
        elapsed = time.time() - start_time
        return elapsed > self.health_check_threshold
    
    def _test_connection(self, connection):
        """ì—°ê²° ìƒíƒœ í™•ì¸"""
        try:
            if connection.closed:
                return False
            with connection.cursor() as cursor:
                cursor.execute("SELECT 1")
                cursor.fetchone()
            return True
        except:
            self._increment_stat('health_checks_failed')
            return False
    
    def return_connection(self, connection):
        """ì—°ê²°ì„ í’€ë¡œ ë°˜í™˜"""
        if not connection:
            return
        
        pool = self._connection_pool or self.pool
        
        try:
            is_pool_connection = False
            with self._pool_connections_lock:
                is_pool_connection = connection in self._pool_connections
            
            if pool and is_pool_connection:
                if self._test_connection(connection):
                    try:
                        pool.putconn(connection)
                        return
                    except Exception as e:
                        logger.warning(f"í’€ë¡œ ì—°ê²° ë°˜í™˜ ì‹¤íŒ¨: {e}")
                
                try:
                    pool.putconn(connection, close=True)
                except:
                    pass
            else:
                try:
                    connection.close()
                except:
                    pass
        
        except Exception as e:
            logger.warning(f"ì—°ê²° ë°˜í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
            try:
                connection.close()
            except:
                pass
    
    def init_pool(self):
        """ì—°ê²° í’€ ì´ˆê¸°í™” (SimpleConnectionPool ì‚¬ìš©)"""
        try:
            if not self._connection_pool and not self.pool:
                from psycopg2 import pool
                from urllib.parse import urlparse
                
                # DATABASE_URL íŒŒì‹±
                parsed = urlparse(self.database_url)
                
                self.pool = pool.SimpleConnectionPool(
                    1,  # ìµœì†Œ ì—°ê²°
                    5,  # ìµœëŒ€ ì—°ê²°
                    host=parsed.hostname,
                    port=parsed.port or 5432,
                    database=parsed.path[1:],
                    user=parsed.username,
                    password=parsed.password
                )
                
                # í˜¸í™˜ì„±ì„ ìœ„í•´ ë‘˜ ë‹¤ ì„¤ì •
                self._connection_pool = self.pool
                
                self.log_info("PostgreSQL ì—°ê²° í’€ ìƒì„± ì™„ë£Œ (SimpleConnectionPool)")
        except Exception as e:
            self.log_error(f"ì—°ê²° í’€ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self._connection_pool = None
            self.pool = None
    
    def close_pool(self):
        """ì—°ê²° í’€ ì¢…ë£Œ"""
        with self._pool_lock:
            pool = self._connection_pool or self.pool
            if pool:
                try:
                    pool.closeall()
                    logger.info("PostgreSQL ì—°ê²° í’€ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤")
                except Exception as e:
                    logger.error(f"ì—°ê²° í’€ ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜: {e}")
                finally:
                    self._connection_pool = None
                    self.pool = None
                    
                with self._pool_connections_lock:
                    self._pool_connections.clear()
    
    def close_connection(self, conn):
        """ì—°ê²° ë°˜í™˜ (í™•ì‹¤íˆ ë‹«ê¸°)"""
        pool = self._connection_pool or self.pool
        if conn and pool:
            try:
                pool.putconn(conn)
            except:
                try:
                    conn.close()
                except:
                    pass
    
    def _get_cache_key(self, query, params):
        """ì¿¼ë¦¬ì™€ íŒŒë¼ë¯¸í„°ë¡œ ìºì‹œ í‚¤ ìƒì„±"""
        query_hash = hashlib.md5(f"{query}_{str(params)}".encode()).hexdigest()
        return query_hash
    
    def _is_cache_valid(self, timestamp):
        """ìºì‹œê°€ ìœ íš¨í•œì§€ í™•ì¸"""
        return time.time() - timestamp < self._cache_ttl
    
    def prepare_statement(self, connection, stmt_name, query):
        """Prepared Statement ìƒì„± ë° ìºì‹œ"""
        with self._prepared_lock:
            if stmt_name not in self._prepared_statements:
                try:
                    with connection.cursor() as cursor:
                        cursor.execute(f"PREPARE {stmt_name} AS {query}")
                    self._prepared_statements[stmt_name] = {
                        'query': query,
                        'created_at': time.time()
                    }
                    logger.info(f"Prepared statement ìƒì„±: {stmt_name}")
                except Exception as e:
                    logger.warning(f"Prepared statement ìƒì„± ì‹¤íŒ¨: {e}")
                    return False
        return True
    
    def execute_prepared(self, stmt_name, params=None, fetch_one=False, fetch_all=False):
        """Prepared Statementë¡œ ì¿¼ë¦¬ ì‹¤í–‰"""
        connection = None
        start_time = time.time()
        self._increment_stat('queries_executed')
        
        try:
            connection = self.get_connection()
            
            with connection.cursor(cursor_factory=psycopg2.extras.RealDictCursor) as cursor:
                safe_params = params if params is not None else ()
                execute_query = f"EXECUTE {stmt_name}"
                if safe_params:
                    execute_query += f" ({','.join(['%s'] * len(safe_params))})"
                
                cursor.execute(execute_query, safe_params)
                
                if fetch_one:
                    result = cursor.fetchone()
                    if result:
                        return dict(result)
                    return None
                elif fetch_all:
                    results = cursor.fetchall()
                    return [dict(row) for row in results]
                else:
                    connection.commit()
                    return cursor.rowcount
                    
        except Exception as e:
            self._increment_stat('query_errors')
            logger.error(f"Prepared statement ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            raise
        finally:
            if connection:
                self.return_connection(connection)
    
    def cached_query(self, query, params=None, fetch_one=False, fetch_all=False, cache_ttl=None):
        """ì¿¼ë¦¬ ê²°ê³¼ ìºì‹±"""
        if cache_ttl is None:
            cache_ttl = self._cache_ttl
            
        cache_key = self._get_cache_key(query, params)
        
        with self._cache_lock:
            if cache_key in self._query_cache:
                cached_data = self._query_cache[cache_key]
                if self._is_cache_valid(cached_data['timestamp']):
                    logger.debug(f"ì¿¼ë¦¬ ìºì‹œ íˆíŠ¸: {cache_key[:8]}...")
                    return cached_data['result']
                else:
                    del self._query_cache[cache_key]
        
        result = self.execute_query(query, params, fetch_one, fetch_all)
        
        with self._cache_lock:
            self._query_cache[cache_key] = {
                'result': result,
                'timestamp': time.time()
            }
            
            if len(self._query_cache) > 1000:
                oldest_key = min(self._query_cache.keys(), 
                               key=lambda k: self._query_cache[k]['timestamp'])
                del self._query_cache[oldest_key]
        
        logger.debug(f"ì¿¼ë¦¬ ê²°ê³¼ ìºì‹œë¨: {cache_key[:8]}...")
        return result

    def execute_query(self, query, params=None, fetch_one=False, fetch_all=False):
        """ì¿¼ë¦¬ ì‹¤í–‰ í—¬í¼ í•¨ìˆ˜"""
        connection = None
        max_retries = 2
        start_time = time.time()
        
        self._increment_stat('queries_executed')
        
        for attempt in range(max_retries):
            try:
                connection = self.get_connection()
                with connection.cursor(cursor_factory=psycopg2.extras.RealDictCursor) as cursor:
                    safe_params = params if params is not None else ()
                    cursor.execute(query, safe_params)
                    
                    if fetch_one:
                        result = cursor.fetchone()
                        if query.strip().upper().startswith(('INSERT', 'UPDATE', 'DELETE')):
                            connection.commit()
                        
                        elapsed_time = time.time() - start_time
                        if elapsed_time > 1.0:
                            logger.info(f"ì¿¼ë¦¬ ì™„ë£Œ (fetch_one): {elapsed_time:.2f}s")
                        
                        return dict(result) if result else None
                    elif fetch_all:
                        results = cursor.fetchall()
                        if query.strip().upper().startswith(('INSERT', 'UPDATE', 'DELETE')):
                            connection.commit()
                        
                        elapsed_time = time.time() - start_time
                        if elapsed_time > 1.0:
                            logger.info(f"ì¿¼ë¦¬ ì™„ë£Œ (fetch_all): {elapsed_time:.2f}s, {len(results)}ê°œ í–‰")
                        
                        return [dict(row) for row in results]
                    else:
                        connection.commit()
                        
                        elapsed_time = time.time() - start_time
                        if elapsed_time > 1.0:
                            logger.info(f"ì¿¼ë¦¬ ì™„ë£Œ (commit): {elapsed_time:.2f}s")
                        
                        return cursor.rowcount
                        
            except (psycopg2.OperationalError, psycopg2.InterfaceError) as e:
                self._increment_stat('query_errors')
                logger.warning(f"ì—°ê²° ì˜¤ë¥˜ ë°œìƒ (ì‹œë„ {attempt + 1}/{max_retries}): {e}")
                
                if connection:
                    pool = self._connection_pool or self.pool
                    try:
                        if pool:
                            pool.putconn(connection, close=True)
                        else:
                            connection.close()
                    except:
                        try:
                            connection.close()
                        except:
                            pass
                    connection = None
                
                if attempt < max_retries - 1:
                    continue
                else:
                    elapsed_time = time.time() - start_time
                    logger.error(f"ì¿¼ë¦¬ ì‹¤í–‰ ì˜¤ë¥˜ (ìµœì¢…, {elapsed_time:.2f}s): {e}")
                    logger.error(f"ì¿¼ë¦¬: {query}")
                    logger.error(f"íŒŒë¼ë¯¸í„°: {params}")
                    raise
                    
            except Exception as e:
                self._increment_stat('query_errors')
                elapsed_time = time.time() - start_time
                logger.error(f"ì¿¼ë¦¬ ì‹¤í–‰ ì˜¤ë¥˜ ({elapsed_time:.2f}s): {e}")
                logger.error(f"ì¿¼ë¦¬: {query}")
                logger.error(f"íŒŒë¼ë¯¸í„°: {params}")
                raise
            finally:
                if connection:
                    try:
                        self.return_connection(connection)
                    except Exception as e:
                        logger.warning(f"ì—°ê²° ë°˜í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
                        try:
                            connection.close()
                        except:
                            pass
            
            break
    
    def execute_many(self, query, params_list):
        """ëŒ€ëŸ‰ ë°ì´í„° ì‚½ì…/ì—…ë°ì´íŠ¸"""
        connection = None
        start_time = time.time()
        self._increment_stat('queries_executed')
        
        try:
            connection = self.get_connection()
            with connection.cursor(cursor_factory=psycopg2.extras.RealDictCursor) as cursor:
                cursor.executemany(query, params_list)
                connection.commit()
                
                elapsed_time = time.time() - start_time
                if elapsed_time > 2.0:
                    logger.info(f"ëŒ€ëŸ‰ ì¿¼ë¦¬ ì™„ë£Œ: {elapsed_time:.2f}s, {len(params_list)}ê°œ ë ˆì½”ë“œ")
                
                return cursor.rowcount
        except Exception as e:
            self._increment_stat('query_errors')
            elapsed_time = time.time() - start_time
            logger.error(f"ëŒ€ëŸ‰ ì¿¼ë¦¬ ì‹¤í–‰ ì˜¤ë¥˜ ({elapsed_time:.2f}s): {e}")
            raise
        finally:
            if connection:
                self.return_connection(connection)
    
    def to_dataframe(self, query, params=None):
        """ì¿¼ë¦¬ ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë°˜í™˜"""
        connection = None
        start_time = time.time()
        self._increment_stat('queries_executed')
        
        try:
            connection = self.get_connection()
            df = pd.read_sql_query(query, connection, params=params)
            
            elapsed_time = time.time() - start_time
            if elapsed_time > 1.0:
                logger.info(f"DataFrame ì¿¼ë¦¬ ì™„ë£Œ: {elapsed_time:.2f}s, {len(df)}ê°œ í–‰")
            
            return df
        except Exception as e:
            self._increment_stat('query_errors')
            elapsed_time = time.time() - start_time
            logger.error(f"DataFrame ë³€í™˜ ì˜¤ë¥˜ ({elapsed_time:.2f}s): {e}")
            return pd.DataFrame()
        finally:
            if connection:
                self.return_connection(connection)
    
    def get_cursor(self, connection=None):
        """ë”•ì…”ë„ˆë¦¬ í˜•íƒœ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” ì»¤ì„œ ìƒì„±"""
        if connection is None:
            connection = self.get_connection()
        return connection.cursor(cursor_factory=psycopg2.extras.RealDictCursor)
    
    def log_info(self, message):
        """ì •ë³´ ë¡œê·¸ ì¶œë ¥"""
        logger.info(message)
        print(f"INFO: {message}")
    
    def log_error(self, message):
        """ì˜¤ë¥˜ ë¡œê·¸ ì¶œë ¥"""
        logger.error(message)
        print(f"ERROR: {message}")
    
    def log_warning(self, message):
        """ê²½ê³  ë¡œê·¸ ì¶œë ¥"""
        logger.warning(message)
        print(f"WARNING: {message}")
    
    def table_exists(self, table_name):
        """í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
        query = """
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_schema = 'public' 
                AND table_name = %s
            );
        """
        try:
            result = self.execute_query(query, (table_name,), fetch_one=True)
            if result and isinstance(result, dict):
                return result.get('exists', False)
            return False
        except Exception as e:
            logger.error(f"í…Œì´ë¸” ì¡´ì¬ í™•ì¸ ì˜¤ë¥˜: {e}")
            return False
    
    def get_table_columns(self, table_name):
        """í…Œì´ë¸” ì»¬ëŸ¼ ì •ë³´ ì¡°íšŒ"""
        query = """
            SELECT column_name, data_type, is_nullable, column_default
            FROM information_schema.columns
            WHERE table_schema = 'public' AND table_name = %s
            ORDER BY ordinal_position;
        """
        try:
            return self.execute_query(query, (table_name,), fetch_all=True)
        except Exception as e:
            logger.error(f"í…Œì´ë¸” ì»¬ëŸ¼ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return []
    
    def create_table_if_not_exists(self, table_name, create_sql):
        """í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±"""
        if not self.table_exists(table_name):
            try:
                self.execute_query(create_sql)
                logger.info(f"í…Œì´ë¸” {table_name} ìƒì„± ì™„ë£Œ")
                return True
            except Exception as e:
                logger.error(f"í…Œì´ë¸” {table_name} ìƒì„± ì˜¤ë¥˜: {e}")
                raise
        else:
            logger.info(f"í…Œì´ë¸” {table_name}ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤")
            return False
    
    def backup_table_data(self, table_name):
        """í…Œì´ë¸” ë°ì´í„° ë°±ì—…"""
        if self.table_exists(table_name):
            query = f"SELECT * FROM {table_name}"
            return self.to_dataframe(query)
        return pd.DataFrame()
    
    def _increment_stat(self, stat_name: str) -> None:
        """ìŠ¤ë ˆë“œ ì•ˆì „í•œ í†µê³„ ì¦ê°€"""
        with self._stats_lock:
            self._pool_stats[stat_name] = self._pool_stats.get(stat_name, 0) + 1
    
    def get_pool_stats(self) -> Dict[str, Any]:
        """ì—°ê²° í’€ í†µê³„ ë°˜í™˜"""
        with self._stats_lock:
            stats: Dict[str, Any] = dict(self._pool_stats)
        
        pool = self._connection_pool or self.pool
        if pool:
            try:
                stats['pool_configured'] = True
                stats['pool_timeout'] = self.pool_timeout
                stats['health_check_enabled'] = self.health_check_enabled
                stats['health_check_threshold'] = self.health_check_threshold
                stats['timestamp'] = datetime.now().isoformat()
                
                with self._pool_connections_lock:
                    stats['tagged_connections'] = len(self._pool_connections)
                
            except Exception as e:
                logger.warning(f"í†µê³„ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
        else:
            stats['pool_configured'] = False
        
        return stats
    
    def _log_pool_stats(self) -> None:
        """ì—°ê²° í’€ í†µê³„ ë¡œê¹…"""
        stats = self.get_pool_stats()
        logger.info(f"PostgreSQL ì—°ê²° í’€ í†µê³„: {stats}")
    
    def reset_pool_stats(self) -> None:
        """í†µê³„ ì´ˆê¸°í™”"""
        with self._stats_lock:
            for key in self._pool_stats:
                self._pool_stats[key] = 0
        logger.info("ì—°ê²° í’€ í†µê³„ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤")
    
    def __del__(self):
        """ì†Œë©¸ìì—ì„œ í’€ ìë™ ì •ë¦¬"""
        try:
            self.close_pool()
        except:
            pass
    
    @staticmethod
    def format_timestamp(dt=None):
        """PostgreSQL íƒ€ì„ìŠ¤íƒ¬í”„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        if dt is None:
            dt = datetime.now()
        return dt.strftime('%Y-%m-%d %H:%M:%S')
    
    @staticmethod
    def hash_password(password: str) -> str:
        """íŒ¨ìŠ¤ì›Œë“œë¥¼ bcryptë¡œ í•´ì‹±í•©ë‹ˆë‹¤"""
        if not password:
            return ""
        
        if not BCRYPT_AVAILABLE:
            logger.critical("ğŸš¨ bcrypt ì—†ì´ íŒ¨ìŠ¤ì›Œë“œ í•´ì‹± ì‹œë„ë¨ - ì‹œìŠ¤í…œ ì¤‘ë‹¨")
            raise ValueError("bcrypt ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install bcrypt' ì‹¤í–‰ í•„ìš”")
        
        try:
            salt = bcrypt.gensalt(rounds=12)
            hashed = bcrypt.hashpw(password.encode('utf-8'), salt)
            logger.debug(f"âœ… íŒ¨ìŠ¤ì›Œë“œ bcrypt í•´ì‹± ì™„ë£Œ (cost=12)")
            return hashed.decode('utf-8')
        except Exception as e:
            logger.error(f"íŒ¨ìŠ¤ì›Œë“œ í•´ì‹± ì‹¤íŒ¨: {e}")
            raise ValueError(f"íŒ¨ìŠ¤ì›Œë“œ í•´ì‹± ì¤‘ ì˜¤ë¥˜: {e}")
    
    @staticmethod
    def verify_password(password: str, hashed_password: str) -> bool:
        """íŒ¨ìŠ¤ì›Œë“œì™€ í•´ì‹œë¥¼ ë¹„êµ ê²€ì¦í•©ë‹ˆë‹¤"""
        if not password or not hashed_password:
            return False
        
        if BasePostgreSQLManager.is_bcrypt_hash(hashed_password):
            if not BCRYPT_AVAILABLE:
                logger.critical("ğŸš¨ bcrypt í•´ì‹œ ê²€ì¦ ì‹œë„ but bcrypt ì—†ìŒ - ë¡œê·¸ì¸ ì‹¤íŒ¨")
                return False
            try:
                result = bcrypt.checkpw(password.encode('utf-8'), hashed_password.encode('utf-8'))
                if result:
                    logger.debug("âœ… bcrypt íŒ¨ìŠ¤ì›Œë“œ ê²€ì¦ ì„±ê³µ")
                return result
            except Exception as e:
                logger.error(f"bcrypt íŒ¨ìŠ¤ì›Œë“œ ê²€ì¦ ì˜¤ë¥˜: {e}")
                return False
        
        elif BasePostgreSQLManager.is_sha256_hash(hashed_password):
            try:
                sha256_hash = hashlib.sha256(password.encode('utf-8')).hexdigest()
                result = sha256_hash == hashed_password
                if result:
                    logger.warning(f"âš ï¸ SHA256 íŒ¨ìŠ¤ì›Œë“œ ê²€ì¦ ì„±ê³µ - bcrypt ì¬í•´ì‹± ê¶Œì¥")
                return result
            except Exception as e:
                logger.error(f"SHA256 íŒ¨ìŠ¤ì›Œë“œ ê²€ì¦ ì˜¤ë¥˜: {e}")
                return False
        
        else:
            result = password == hashed_password
            if result:
                logger.critical(f"ğŸš¨ PLAINTEXT íŒ¨ìŠ¤ì›Œë“œ ê²€ì¦ë¨ - ì¦‰ì‹œ bcrypt ì¬í•´ì‹± í•„ìš”!")
            return result
    
    @staticmethod
    def is_hashed_password(password: str) -> bool:
        """íŒ¨ìŠ¤ì›Œë“œê°€ ì´ë¯¸ í•´ì‹œëœ ìƒíƒœì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤"""
        if not password:
            return False
        return BasePostgreSQLManager.is_bcrypt_hash(password)
    
    @staticmethod
    def is_bcrypt_hash(password: str) -> bool:
        """bcrypt í•´ì‹œì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤"""
        if not password:
            return False
        
        if len(password) != 60:
            return False
        
        if not (password.startswith('$2a$') or 
                password.startswith('$2b$') or 
                password.startswith('$2y$')):
            return False
        
        try:
            cost_part = password[4:6]
            int(cost_part)
            return password[6] == '$'
        except (ValueError, IndexError):
            return False
    
    @staticmethod
    def is_sha256_hash(password: str) -> bool:
        """SHA256 í•´ì‹œì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤"""
        if not password:
            return False
        return len(password) == 64 and all(c in '0123456789abcdef' for c in password.lower())
    
    @staticmethod
    def should_rehash_password(hashed_password: str) -> bool:
        """íŒ¨ìŠ¤ì›Œë“œ ì¬í•´ì‹±ì´ í•„ìš”í•œì§€ í™•ì¸í•©ë‹ˆë‹¤"""
        if not hashed_password:
            return True
        
        if not BasePostgreSQLManager.is_bcrypt_hash(hashed_password):
            return True
        
        if BCRYPT_AVAILABLE:
            try:
                cost_match = re.search(r'\$2[aby]\$(\d{2})\$', hashed_password)
                if cost_match:
                    cost = int(cost_match.group(1))
                    return cost < 12
            except:
                pass
        
        return False
