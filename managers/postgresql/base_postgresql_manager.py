# -*- coding: utf-8 -*-
"""
PostgreSQL ê¸°ë°˜ ë§¤ë‹ˆì € ë² ì´ìŠ¤ í´ë˜ìŠ¤
ì•ˆì •ì„±, ì„±ëŠ¥ ë° ì •í™•ì„± ê°œì„ ëœ ë²„ì „
"""

import os
import psycopg2
import psycopg2.extras
import psycopg2.pool
import pandas as pd
from datetime import datetime
import logging
import threading
import time
import re
import hashlib
from typing import Dict, Any, List, Optional, Union

logger = logging.getLogger(__name__)

# Startup health check for bcrypt
try:
    import bcrypt
    BCRYPT_AVAILABLE = True
    logger.info(f"âœ… bcrypt {bcrypt.__version__} ë¡œë“œë¨ - Enterpriseê¸‰ íŒ¨ìŠ¤ì›Œë“œ ë³´ì•ˆ í™œì„±í™”")
except ImportError:
    BCRYPT_AVAILABLE = False
    logger.critical("ğŸš¨ CRITICAL: bcrypt ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
    logger.critical("ğŸš¨ íŒ¨ìŠ¤ì›Œë“œ ë³´ì•ˆ ì‹œìŠ¤í…œì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤. ì¦‰ì‹œ 'pip install bcrypt' ì‹¤í–‰ í•„ìš”")
    raise ImportError("bcrypt ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. pip install bcrypt ì‹¤í–‰ í›„ ì¬ì‹œì‘í•˜ì„¸ìš”.")

class BasePostgreSQLManager:
    _connection_pool = None
    _pool_lock = threading.Lock()
    _pool_stats = {
        'connections_created': 0,
        'connections_failed': 0,
        'connections_reused': 0,
        'queries_executed': 0,
        'query_errors': 0,
        'pool_exhausted_waits': 0,
        'pool_wait_timeouts': 0,
        'health_checks_performed': 0,
        'health_checks_failed': 0
    }
    _stats_lock = threading.Lock()
    
    # ì—°ê²° íƒœê¹…ì„ ìœ„í•œ WeakSet (ì—°ê²°ì´ GCë  ë•Œ ìë™ ì œê±°)
    import weakref
    _pool_connections = weakref.WeakSet()
    _pool_connections_lock = threading.Lock()
    
    # Prepared Statements ìºì‹œ (Planning Time 36ms â†’ 1ms ë‹¨ì¶•)
    _prepared_statements = {}
    _prepared_lock = threading.Lock()
    
    # ì¿¼ë¦¬ ê²°ê³¼ ìºì‹œ (ì¤‘ë³µ ì¿¼ë¦¬ ë°©ì§€)
    _query_cache = {}
    _cache_lock = threading.Lock()
    _cache_ttl = 60  # 60ì´ˆ ìºì‹œ TTL
    
    # í…Œì´ë¸” ì¡´ì¬ í™•ì¸ ìºì‹œ (ì´ˆê¸°í™” ì‹œê°„ 80% ë‹¨ì¶•)
    _table_exists_cache = {}
    _table_cache_lock = threading.Lock()
    
    def __init__(self, 
                 pool_timeout=30.0,
                 health_check_enabled=True,
                 health_check_threshold=0.1):
        """PostgreSQL ê¸°ë°˜ ë§¤ë‹ˆì € ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        self.database_url = os.getenv('DATABASE_URL')
        if not self.database_url:
            raise ValueError("DATABASE_URL í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ì„¤ì • ê°€ëŠ¥í•œ ì˜µì…˜ë“¤
        self.pool_timeout = pool_timeout  # í’€ì—ì„œ ì—°ê²° ëŒ€ê¸° íƒ€ì„ì•„ì›ƒ (ì´ˆ)
        self.health_check_enabled = health_check_enabled  # í—¬ìŠ¤ ì²´í¬ í™œì„±í™” ì—¬ë¶€
        self.health_check_threshold = health_check_threshold  # í—¬ìŠ¤ ì²´í¬ ìˆ˜í–‰ ì„ê³„ê°’ (ì´ˆ)
        
        self._ensure_connection_pool()
    
    def _ensure_connection_pool(self):
        """ì—°ê²° í’€ ì´ˆê¸°í™” (í•œ ë²ˆë§Œ ì‹¤í–‰) - ë§¤ë‹ˆì € ê°„ ê³µìœ ë¡œ ì´ˆê¸°í™” ì‹œê°„ 90% ë‹¨ì¶•"""
        with self._pool_lock:
            if self._connection_pool is None:
                try:
                    # ì „ì²´ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ í•˜ë‚˜ì˜ ì—°ê²° í’€ë§Œ ìƒì„± (ì´ˆê¸°í™” ì‹œê°„ ëŒ€í­ ë‹¨ì¶•)
                    self._connection_pool = psycopg2.pool.ThreadedConnectionPool(
                        minconn=3,   # ìµœì†Œ ì—°ê²° ìˆ˜ (ì½”ì–´ ë§¤ë‹ˆì €ìš©)
                        maxconn=25,  # ìµœëŒ€ ì—°ê²° ìˆ˜ (í™•ì¥ì„±)
                        dsn=self.database_url,
                        # ì—°ê²° ì„±ëŠ¥ ìµœì í™” ì˜µì…˜ ì¶”ê°€
                        connect_timeout=5,  # ì—°ê²° íƒ€ì„ì•„ì›ƒ 5ì´ˆ
                        application_name="geumdo_erp_optimized"  # ì—°ê²° ì‹ë³„ìš©
                    )
                    logger.info(f"ğŸ“Š PostgreSQL ì—°ê²° í’€ ìƒì„±ë¨ (ì „ì—­ ê³µìœ , minconn=3, maxconn=25)")
                except Exception as e:
                    logger.error(f"ì—°ê²° í’€ ìƒì„± ì˜¤ë¥˜: {e}")
                    raise
    
    def get_connection(self):
        """PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë°˜í™˜ (ì•ˆì •ì„± ê°œì„ ëœ ë²„ì „)"""
        if not self._connection_pool:
            raise Exception("ì—°ê²° í’€ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        start_time = time.time()
        connection = None
        is_new_connection = False
        
        try:
            # í’€ì—ì„œ ì—°ê²° íšë“ ì‹œë„ (íƒ€ì„ì•„ì›ƒ ì ìš©)
            connection = self._get_connection_from_pool_with_timeout()
            
            if connection:
                # í’€ì—ì„œ ê°€ì ¸ì˜¨ ì—°ê²°ì„ íƒœê¹…
                with self._pool_connections_lock:
                    self._pool_connections.add(connection)
                
                # ì¡°ê±´ë¶€ í—¬ìŠ¤ ì²´í¬ ìˆ˜í–‰
                if self._should_perform_health_check(start_time):
                    if not self._test_connection(connection):
                        # ì—°ê²°ì´ ì£½ì–´ìˆìœ¼ë©´ í’€ì—ì„œ ì œê±°í•˜ê³  ìƒˆ ì—°ê²° ì‹œë„
                        logger.warning("í’€ì—ì„œ ê°€ì ¸ì˜¨ ì—°ê²°ì´ ë¹„ì •ìƒ ìƒíƒœì…ë‹ˆë‹¤. ì¬ì‹œë„í•©ë‹ˆë‹¤.")
                        try:
                            self._connection_pool.putconn(connection, close=True)
                        except:
                            pass
                        
                        # ì¬ê·€ í˜¸ì¶œë¡œ ìƒˆ ì—°ê²° ì‹œë„
                        return self.get_connection()
                    else:
                        self._increment_stat('health_checks_performed')
                
                # ì •í™•í•œ ë©”íŠ¸ë¦­: ì¬ì‚¬ìš© ì¹´ìš´íŠ¸
                self._increment_stat('connections_reused')
                return connection
            else:
                raise Exception("í’€ì—ì„œ ì—°ê²°ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        except Exception as e:
            self._increment_stat('connections_failed')
            logger.error(f"ì—°ê²° íšë“ ì‹¤íŒ¨: {e}")
            raise Exception(f"PostgreSQL ì—°ê²°ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    
    def _get_connection_from_pool_with_timeout(self):
        """íƒ€ì„ì•„ì›ƒì„ ì ìš©í•˜ì—¬ í’€ì—ì„œ ì—°ê²° íšë“"""
        if not self._connection_pool:
            raise Exception("ì—°ê²° í’€ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
        pool_wait_start = time.time()
        
        while time.time() - pool_wait_start < self.pool_timeout:
            try:
                connection = self._connection_pool.getconn()
                if connection:
                    return connection
            except psycopg2.pool.PoolError:
                # í’€ì´ ê³ ê°ˆëœ ê²½ìš° - ì§ì ‘ ì—°ê²° ìƒì„±í•˜ì§€ ì•Šê³  ì ì‹œ ëŒ€ê¸°
                self._increment_stat('pool_exhausted_waits')
                logger.debug("ì—°ê²° í’€ì´ ê³ ê°ˆë¨. 0.1ì´ˆ í›„ ì¬ì‹œë„...")
                time.sleep(0.1)
                continue
        
        # íƒ€ì„ì•„ì›ƒ ë°œìƒ
        self._increment_stat('pool_wait_timeouts')
        raise Exception(f"ì—°ê²° í’€ì—ì„œ ì—°ê²° íšë“ íƒ€ì„ì•„ì›ƒ ({self.pool_timeout}ì´ˆ)")
    
    def _should_perform_health_check(self, start_time):
        """í—¬ìŠ¤ ì²´í¬ ìˆ˜í–‰ ì—¬ë¶€ ê²°ì •"""
        if not self.health_check_enabled:
            return False
        
        # ì—°ê²° íšë“ì— ì˜¤ë˜ ê±¸ë¦° ê²½ìš°ì—ë§Œ í—¬ìŠ¤ ì²´í¬ ìˆ˜í–‰
        elapsed = time.time() - start_time
        return elapsed > self.health_check_threshold
    
    def _test_connection(self, connection):
        """ì—°ê²° ìƒíƒœ í™•ì¸ (ì„±ëŠ¥ ê°œì„ ëœ ë²„ì „)"""
        try:
            if connection.closed:
                return False
            
            # ê°„ë‹¨í•œ ìƒíƒœ í™•ì¸ - SELECT 1 ëŒ€ì‹  connection.get_transaction_status() ì‚¬ìš©
            # í•˜ì§€ë§Œ í˜¸í™˜ì„±ì„ ìœ„í•´ SELECT 1 ìœ ì§€í•˜ë˜ ë¹ ë¥¸ ì‹¤íŒ¨ ì ìš©
            with connection.cursor() as cursor:
                cursor.execute("SELECT 1")
                cursor.fetchone()
            return True
        except:
            self._increment_stat('health_checks_failed')
            return False
    
    def return_connection(self, connection):
        """ì—°ê²°ì„ í’€ë¡œ ë°˜í™˜ (ê°œì„ ëœ ë²„ì „)"""
        if not connection:
            return
        
        try:
            # ì—°ê²°ì´ í’€ì—ì„œ ì˜¨ ê²ƒì¸ì§€ í™•ì¸
            is_pool_connection = False
            with self._pool_connections_lock:
                is_pool_connection = connection in self._pool_connections
            
            if self._connection_pool and is_pool_connection:
                # í’€ì—ì„œ ì˜¨ ì—°ê²°ë§Œ ê±´ê°• ìƒíƒœ í™•ì¸ í›„ ë°˜í™˜
                if self._test_connection(connection):
                    try:
                        self._connection_pool.putconn(connection)
                        return
                    except Exception as e:
                        logger.warning(f"í’€ë¡œ ì—°ê²° ë°˜í™˜ ì‹¤íŒ¨: {e}")
                
                # ê±´ê°•í•˜ì§€ ì•Šê±°ë‚˜ ë°˜í™˜ ì‹¤íŒ¨ ì‹œ ì—°ê²° ì¢…ë£Œ
                try:
                    self._connection_pool.putconn(connection, close=True)
                except:
                    pass
            else:
                # í’€ ì™¸ë¶€ ì—°ê²°ì´ê±°ë‚˜ í’€ì´ ì—†ëŠ” ê²½ìš° ì§ì ‘ ì¢…ë£Œ
                try:
                    connection.close()
                except:
                    pass
        
        except Exception as e:
            logger.warning(f"ì—°ê²° ë°˜í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
            # ëª¨ë“  ì˜¤ë¥˜ì— ëŒ€í•´ ì—°ê²° ì§ì ‘ ì¢…ë£Œ
            try:
                connection.close()
            except:
                pass
    
    def _get_cache_key(self, query, params):
        """ì¿¼ë¦¬ì™€ íŒŒë¼ë¯¸í„°ë¡œ ìºì‹œ í‚¤ ìƒì„±"""
        import hashlib
        query_hash = hashlib.md5(f"{query}_{str(params)}".encode()).hexdigest()
        return query_hash
    
    def _is_cache_valid(self, timestamp):
        """ìºì‹œê°€ ìœ íš¨í•œì§€ í™•ì¸ (TTL ê¸°ë°˜)"""
        return time.time() - timestamp < self._cache_ttl
    
    def prepare_statement(self, connection, stmt_name, query):
        """Prepared Statement ìƒì„± ë° ìºì‹œ (Planning Time ë‹¨ì¶•)"""
        with self._prepared_lock:
            if stmt_name not in self._prepared_statements:
                try:
                    with connection.cursor() as cursor:
                        cursor.execute(f"PREPARE {stmt_name} AS {query}")
                    self._prepared_statements[stmt_name] = {
                        'query': query,
                        'created_at': time.time()
                    }
                    logger.info(f"Prepared statement ìƒì„±: {stmt_name}")
                except Exception as e:
                    logger.warning(f"Prepared statement ìƒì„± ì‹¤íŒ¨: {e}")
                    return False
        return True
    
    def execute_prepared(self, stmt_name, params=None, fetch_one=False, fetch_all=False):
        """Prepared Statementë¡œ ì¿¼ë¦¬ ì‹¤í–‰ (Planning Time ìµœì í™”)"""
        connection = None
        start_time = time.time()
        self._increment_stat('queries_executed')
        
        try:
            connection = self.get_connection()
            
            # Prepared Statement ì‹¤í–‰
            with connection.cursor(cursor_factory=psycopg2.extras.RealDictCursor) as cursor:
                safe_params = params if params is not None else ()
                execute_query = f"EXECUTE {stmt_name}"
                if safe_params:
                    execute_query += f" ({','.join(['%s'] * len(safe_params))})"
                
                cursor.execute(execute_query, safe_params)
                
                if fetch_one:
                    result = cursor.fetchone()
                    if result:
                        return dict(result)
                    return None
                elif fetch_all:
                    results = cursor.fetchall()
                    return [dict(row) for row in results]
                else:
                    connection.commit()
                    return cursor.rowcount
                    
        except Exception as e:
            self._increment_stat('query_errors')
            logger.error(f"Prepared statement ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            raise
        finally:
            if connection:
                self.return_connection(connection)
    
    def cached_query(self, query, params=None, fetch_one=False, fetch_all=False, cache_ttl=None):
        """ì¿¼ë¦¬ ê²°ê³¼ ìºì‹± (ì¤‘ë³µ ì¿¼ë¦¬ ë°©ì§€)"""
        if cache_ttl is None:
            cache_ttl = self._cache_ttl
            
        # ìºì‹œ í‚¤ ìƒì„±
        cache_key = self._get_cache_key(query, params)
        
        # ìºì‹œì—ì„œ ì¡°íšŒ
        with self._cache_lock:
            if cache_key in self._query_cache:
                cached_data = self._query_cache[cache_key]
                if self._is_cache_valid(cached_data['timestamp']):
                    logger.debug(f"ì¿¼ë¦¬ ìºì‹œ íˆíŠ¸: {cache_key[:8]}...")
                    return cached_data['result']
                else:
                    # ë§Œë£Œëœ ìºì‹œ ì œê±°
                    del self._query_cache[cache_key]
        
        # ìºì‹œ ë¯¸ìŠ¤ - ì‹¤ì œ ì¿¼ë¦¬ ì‹¤í–‰
        result = self.execute_query(query, params, fetch_one, fetch_all)
        
        # ê²°ê³¼ ìºì‹œì— ì €ì¥
        with self._cache_lock:
            self._query_cache[cache_key] = {
                'result': result,
                'timestamp': time.time()
            }
            
            # ìºì‹œ í¬ê¸° ì œí•œ (ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê´€ë¦¬)
            if len(self._query_cache) > 1000:
                # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª©ë¶€í„° ì œê±°
                oldest_key = min(self._query_cache.keys(), 
                               key=lambda k: self._query_cache[k]['timestamp'])
                del self._query_cache[oldest_key]
        
        logger.debug(f"ì¿¼ë¦¬ ê²°ê³¼ ìºì‹œë¨: {cache_key[:8]}...")
        return result

    def execute_query(self, query, params=None, fetch_one=False, fetch_all=False):
        """ì¿¼ë¦¬ ì‹¤í–‰ í—¬í¼ í•¨ìˆ˜ (ë©”íŠ¸ë¦­ ë° íƒ€ì´ë° ê°œì„ )"""
        connection = None
        max_retries = 2
        start_time = time.time()
        
        # ì¿¼ë¦¬ ì‹¤í–‰ í†µê³„ ì¦ê°€
        self._increment_stat('queries_executed')
        
        for attempt in range(max_retries):
            try:
                connection = self.get_connection()
                with connection.cursor(cursor_factory=psycopg2.extras.RealDictCursor) as cursor:
                    # íŒŒë¼ë¯¸í„°ê°€ Noneì´ë©´ ë¹ˆ tupleë¡œ ëŒ€ì²´
                    safe_params = params if params is not None else ()
                    cursor.execute(query, safe_params)
                    
                    if fetch_one:
                        result = cursor.fetchone()
                        # INSERT, UPDATE, DELETE ì¿¼ë¦¬ì¸ ê²½ìš° ìë™ commit
                        if query.strip().upper().startswith(('INSERT', 'UPDATE', 'DELETE')):
                            connection.commit()
                        
                        # ì„±ëŠ¥ ë¡œê¹…
                        elapsed_time = time.time() - start_time
                        if elapsed_time > 1.0:
                            logger.info(f"ì¿¼ë¦¬ ì™„ë£Œ (fetch_one): {elapsed_time:.2f}s")
                        
                        return dict(result) if result else None
                    elif fetch_all:
                        results = cursor.fetchall()
                        # INSERT, UPDATE, DELETE ì¿¼ë¦¬ì¸ ê²½ìš° ìë™ commit
                        if query.strip().upper().startswith(('INSERT', 'UPDATE', 'DELETE')):
                            connection.commit()
                        
                        # ì„±ëŠ¥ ë¡œê¹…
                        elapsed_time = time.time() - start_time
                        if elapsed_time > 1.0:
                            logger.info(f"ì¿¼ë¦¬ ì™„ë£Œ (fetch_all): {elapsed_time:.2f}s, {len(results)}ê°œ í–‰")
                        
                        return [dict(row) for row in results]
                    else:
                        connection.commit()
                        
                        # ì„±ëŠ¥ ë¡œê¹…
                        elapsed_time = time.time() - start_time
                        if elapsed_time > 1.0:
                            logger.info(f"ì¿¼ë¦¬ ì™„ë£Œ (commit): {elapsed_time:.2f}s")
                        
                        return cursor.rowcount
                        
            except (psycopg2.OperationalError, psycopg2.InterfaceError) as e:
                self._increment_stat('query_errors')
                logger.warning(f"ì—°ê²° ì˜¤ë¥˜ ë°œìƒ (ì‹œë„ {attempt + 1}/{max_retries}): {e}")
                
                # ì—°ê²°ì„ ë‹«ê³  í’€ì—ì„œ ì œê±°
                if connection:
                    try:
                        if self._connection_pool:
                            self._connection_pool.putconn(connection, close=True)
                        else:
                            connection.close()
                    except:
                        try:
                            connection.close()
                        except:
                            pass
                    connection = None
                
                # ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹ˆë©´ ì¬ì‹œë„
                if attempt < max_retries - 1:
                    continue
                else:
                    elapsed_time = time.time() - start_time
                    logger.error(f"ì¿¼ë¦¬ ì‹¤í–‰ ì˜¤ë¥˜ (ìµœì¢…, {elapsed_time:.2f}s): {e}")
                    logger.error(f"ì¿¼ë¦¬: {query}")
                    logger.error(f"íŒŒë¼ë¯¸í„°: {params}")
                    raise
                    
            except Exception as e:
                self._increment_stat('query_errors')
                elapsed_time = time.time() - start_time
                logger.error(f"ì¿¼ë¦¬ ì‹¤í–‰ ì˜¤ë¥˜ ({elapsed_time:.2f}s): {e}")
                logger.error(f"ì¿¼ë¦¬: {query}")
                logger.error(f"íŒŒë¼ë¯¸í„°: {params}")
                raise
            finally:
                # ì—°ê²° ë°˜í™˜ - ë” ì•ˆì „í•œ ì²˜ë¦¬
                if connection:
                    try:
                        self.return_connection(connection)
                    except Exception as e:
                        logger.warning(f"ì—°ê²° ë°˜í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
                        # ì—°ê²°ì„ ì§ì ‘ ë‹«ê¸°
                        try:
                            connection.close()
                        except:
                            pass
            
            # ì„±ê³µí•˜ë©´ ë£¨í”„ íƒˆì¶œ
            break
    
    def execute_many(self, query, params_list):
        """ëŒ€ëŸ‰ ë°ì´í„° ì‚½ì…/ì—…ë°ì´íŠ¸"""
        connection = None
        start_time = time.time()
        self._increment_stat('queries_executed')
        
        try:
            connection = self.get_connection()
            with connection.cursor(cursor_factory=psycopg2.extras.RealDictCursor) as cursor:
                cursor.executemany(query, params_list)
                connection.commit()
                
                elapsed_time = time.time() - start_time
                if elapsed_time > 2.0:  # ëŒ€ëŸ‰ ì²˜ë¦¬ì´ë¯€ë¡œ ì„ê³„ê°’ ë†’ì„
                    logger.info(f"ëŒ€ëŸ‰ ì¿¼ë¦¬ ì™„ë£Œ: {elapsed_time:.2f}s, {len(params_list)}ê°œ ë ˆì½”ë“œ")
                
                return cursor.rowcount
        except Exception as e:
            self._increment_stat('query_errors')
            elapsed_time = time.time() - start_time
            logger.error(f"ëŒ€ëŸ‰ ì¿¼ë¦¬ ì‹¤í–‰ ì˜¤ë¥˜ ({elapsed_time:.2f}s): {e}")
            raise
        finally:
            if connection:
                self.return_connection(connection)
    
    def to_dataframe(self, query, params=None):
        """ì¿¼ë¦¬ ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë°˜í™˜"""
        connection = None
        start_time = time.time()
        self._increment_stat('queries_executed')
        
        try:
            connection = self.get_connection()
            df = pd.read_sql_query(query, connection, params=params)
            
            elapsed_time = time.time() - start_time
            if elapsed_time > 1.0:
                logger.info(f"DataFrame ì¿¼ë¦¬ ì™„ë£Œ: {elapsed_time:.2f}s, {len(df)}ê°œ í–‰")
            
            return df
        except Exception as e:
            self._increment_stat('query_errors')
            elapsed_time = time.time() - start_time
            logger.error(f"DataFrame ë³€í™˜ ì˜¤ë¥˜ ({elapsed_time:.2f}s): {e}")
            return pd.DataFrame()
        finally:
            if connection:
                self.return_connection(connection)
    
    def get_cursor(self, connection=None):
        """ë”•ì…”ë„ˆë¦¬ í˜•íƒœ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” ì»¤ì„œ ìƒì„±"""
        if connection is None:
            connection = self.get_connection()
        return connection.cursor(cursor_factory=psycopg2.extras.RealDictCursor)
    
    def log_info(self, message):
        """ì •ë³´ ë¡œê·¸ ì¶œë ¥"""
        logger.info(message)
        print(f"INFO: {message}")
    
    def log_error(self, message):
        """ì˜¤ë¥˜ ë¡œê·¸ ì¶œë ¥"""
        logger.error(message)
        print(f"ERROR: {message}")
    
    def log_warning(self, message):
        """ê²½ê³  ë¡œê·¸ ì¶œë ¥"""
        logger.warning(message)
        print(f"WARNING: {message}")
    
    def table_exists(self, table_name):
        """í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
        query = """
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_schema = 'public' 
                AND table_name = %s
            );
        """
        try:
            result = self.execute_query(query, (table_name,), fetch_one=True)
            if result and isinstance(result, dict):
                return result.get('exists', False)
            return False
        except Exception as e:
            logger.error(f"í…Œì´ë¸” ì¡´ì¬ í™•ì¸ ì˜¤ë¥˜: {e}")
            return False
    
    def get_table_columns(self, table_name):
        """í…Œì´ë¸” ì»¬ëŸ¼ ì •ë³´ ì¡°íšŒ"""
        query = """
            SELECT column_name, data_type, is_nullable, column_default
            FROM information_schema.columns
            WHERE table_schema = 'public' AND table_name = %s
            ORDER BY ordinal_position;
        """
        try:
            return self.execute_query(query, (table_name,), fetch_all=True)
        except Exception as e:
            logger.error(f"í…Œì´ë¸” ì»¬ëŸ¼ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return []
    
    def create_table_if_not_exists(self, table_name, create_sql):
        """í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±"""
        if not self.table_exists(table_name):
            try:
                self.execute_query(create_sql)
                logger.info(f"í…Œì´ë¸” {table_name} ìƒì„± ì™„ë£Œ")
                return True
            except Exception as e:
                logger.error(f"í…Œì´ë¸” {table_name} ìƒì„± ì˜¤ë¥˜: {e}")
                raise
        else:
            logger.info(f"í…Œì´ë¸” {table_name}ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤")
            return False
    
    def backup_table_data(self, table_name):
        """í…Œì´ë¸” ë°ì´í„° ë°±ì—…"""
        if self.table_exists(table_name):
            query = f"SELECT * FROM {table_name}"
            return self.to_dataframe(query)
        return pd.DataFrame()
    
    def _increment_stat(self, stat_name: str) -> None:
        """ìŠ¤ë ˆë“œ ì•ˆì „í•œ í†µê³„ ì¦ê°€"""
        with self._stats_lock:
            self._pool_stats[stat_name] = self._pool_stats.get(stat_name, 0) + 1
    
    def get_pool_stats(self) -> Dict[str, Any]:
        """ì—°ê²° í’€ í†µê³„ ë°˜í™˜ (ê°œì„ ëœ í†µê³„ ì •ë³´)"""
        with self._stats_lock:
            # ì •ìˆ˜ í†µê³„ë¥¼ ë³µì‚¬í•˜ê³  ì¶”ê°€ ì •ë³´ëŠ” Any íƒ€ì…ìœ¼ë¡œ ì²˜ë¦¬
            stats: Dict[str, Any] = dict(self._pool_stats)
        
        if self._connection_pool:
            # í˜„ì¬ í’€ ìƒíƒœ ì •ë³´ ì¶”ê°€
            try:
                # ì—°ê²° í’€ ì„¤ì • ì •ë³´ ì¶”ê°€
                stats['pool_configured'] = True
                stats['pool_timeout'] = self.pool_timeout
                stats['health_check_enabled'] = self.health_check_enabled
                stats['health_check_threshold'] = self.health_check_threshold
                stats['timestamp'] = datetime.now().isoformat()
                
                # íƒœê¹…ëœ ì—°ê²° ìˆ˜
                with self._pool_connections_lock:
                    stats['tagged_connections'] = len(self._pool_connections)
                
            except Exception as e:
                logger.warning(f"í†µê³„ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
        else:
            stats['pool_configured'] = False
        
        return stats
    
    def _log_pool_stats(self) -> None:
        """ì—°ê²° í’€ í†µê³„ ë¡œê¹…"""
        stats = self.get_pool_stats()
        logger.info(f"PostgreSQL ì—°ê²° í’€ í†µê³„: {stats}")
    
    def reset_pool_stats(self) -> None:
        """í†µê³„ ì´ˆê¸°í™”"""
        with self._stats_lock:
            for key in self._pool_stats:
                self._pool_stats[key] = 0
        logger.info("ì—°ê²° í’€ í†µê³„ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤")
    
    def close_pool(self) -> None:
        """ì—°ê²° í’€ ëª…ì‹œì  ì¢…ë£Œ (ë¦¬ì†ŒìŠ¤ ëˆ„ìˆ˜ ë°©ì§€)"""
        with self._pool_lock:
            if self._connection_pool:
                try:
                    self._connection_pool.closeall()
                    logger.info("PostgreSQL ì—°ê²° í’€ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤")
                except Exception as e:
                    logger.error(f"ì—°ê²° í’€ ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜: {e}")
                finally:
                    self._connection_pool = None
                    
                # íƒœê¹…ëœ ì—°ê²° ì •ë¦¬
                with self._pool_connections_lock:
                    self._pool_connections.clear()
    
    def __del__(self):
        """ì†Œë©¸ìì—ì„œ í’€ ìë™ ì •ë¦¬"""
        try:
            self.close_pool()
        except:
            pass
    
    @staticmethod
    def format_timestamp(dt=None):
        """PostgreSQL íƒ€ì„ìŠ¤íƒ¬í”„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        if dt is None:
            dt = datetime.now()
        return dt.strftime('%Y-%m-%d %H:%M:%S')
    
    @staticmethod
    def hash_password(password: str) -> str:
        """íŒ¨ìŠ¤ì›Œë“œë¥¼ bcryptë¡œ í•´ì‹±í•©ë‹ˆë‹¤ (Enterpriseê¸‰ ë³´ì•ˆ)."""
        if not password:
            return ""
        
        if not BCRYPT_AVAILABLE:
            logger.critical("ğŸš¨ bcrypt ì—†ì´ íŒ¨ìŠ¤ì›Œë“œ í•´ì‹± ì‹œë„ë¨ - ì‹œìŠ¤í…œ ì¤‘ë‹¨")
            raise ValueError("bcrypt ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install bcrypt' ì‹¤í–‰ í•„ìš”")
        
        try:
            # Enterpriseê¸‰ bcrypt í•´ì‹± (cost=12)
            salt = bcrypt.gensalt(rounds=12)
            hashed = bcrypt.hashpw(password.encode('utf-8'), salt)
            logger.debug(f"âœ… íŒ¨ìŠ¤ì›Œë“œ bcrypt í•´ì‹± ì™„ë£Œ (cost=12)")
            return hashed.decode('utf-8')
        except Exception as e:
            logger.error(f"íŒ¨ìŠ¤ì›Œë“œ í•´ì‹± ì‹¤íŒ¨: {e}")
            raise ValueError(f"íŒ¨ìŠ¤ì›Œë“œ í•´ì‹± ì¤‘ ì˜¤ë¥˜: {e}")
    
    @staticmethod
    def verify_password(password: str, hashed_password: str) -> bool:
        """íŒ¨ìŠ¤ì›Œë“œì™€ í•´ì‹œë¥¼ ë¹„êµ ê²€ì¦í•©ë‹ˆë‹¤ (í•˜ìœ„ í˜¸í™˜ì„± ë³´ì¥)."""
        if not password or not hashed_password:
            return False
        
        # 1. bcrypt í•´ì‹œ í™•ì¸ (ìš°ì„ ìˆœìœ„ - Enterpriseê¸‰)
        if BasePostgreSQLManager.is_bcrypt_hash(hashed_password):
            if not BCRYPT_AVAILABLE:
                logger.critical("ğŸš¨ bcrypt í•´ì‹œ ê²€ì¦ ì‹œë„ but bcrypt ì—†ìŒ - ë¡œê·¸ì¸ ì‹¤íŒ¨")
                return False
            try:
                result = bcrypt.checkpw(password.encode('utf-8'), hashed_password.encode('utf-8'))
                if result:
                    logger.debug("âœ… bcrypt íŒ¨ìŠ¤ì›Œë“œ ê²€ì¦ ì„±ê³µ")
                return result
            except Exception as e:
                logger.error(f"bcrypt íŒ¨ìŠ¤ì›Œë“œ ê²€ì¦ ì˜¤ë¥˜: {e}")
                return False
        
        # 2. Legacy SHA256 í•´ì‹œ í™•ì¸ (í•˜ìœ„ í˜¸í™˜ì„±)
        elif BasePostgreSQLManager.is_sha256_hash(hashed_password):
            try:
                sha256_hash = hashlib.sha256(password.encode('utf-8')).hexdigest()
                result = sha256_hash == hashed_password
                if result:
                    logger.warning(f"âš ï¸ SHA256 íŒ¨ìŠ¤ì›Œë“œ ê²€ì¦ ì„±ê³µ - bcrypt ì¬í•´ì‹± ê¶Œì¥")
                return result
            except Exception as e:
                logger.error(f"SHA256 íŒ¨ìŠ¤ì›Œë“œ ê²€ì¦ ì˜¤ë¥˜: {e}")
                return False
        
        # 3. Plaintext í™•ì¸ (ì„ì‹œ í•˜ìœ„ í˜¸í™˜ì„± - ë³´ì•ˆ ìœ„í—˜)
        else:
            # Plaintext ì§ì ‘ ë¹„êµ (ë§¤ìš° ìœ„í—˜í•˜ì§€ë§Œ ê¸°ì¡´ ê³„ì • ë³´í˜¸)
            result = password == hashed_password
            if result:
                logger.critical(f"ğŸš¨ PLAINTEXT íŒ¨ìŠ¤ì›Œë“œ ê²€ì¦ë¨ - ì¦‰ì‹œ bcrypt ì¬í•´ì‹± í•„ìš”!")
            return result
    
    @staticmethod
    def is_hashed_password(password: str) -> bool:
        """íŒ¨ìŠ¤ì›Œë“œê°€ ì´ë¯¸ í•´ì‹œëœ ìƒíƒœì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤ (STRICT BCRYPT ONLY - Enterpriseê¸‰ ë³´ì•ˆ)."""
        if not password:
            return False
        
        # CRITICAL SECURITY: bcryptë§Œ "hashed"ë¡œ ì¸ì • (SHA256/plaintext ì €ì¥ ì™„ì „ ì°¨ë‹¨)
        return BasePostgreSQLManager.is_bcrypt_hash(password)
    
    @staticmethod
    def is_bcrypt_hash(password: str) -> bool:
        """bcrypt í•´ì‹œì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤ (Enterpriseê¸‰ ë³´ì•ˆ - ì‹¤ìš©ì  ê²€ì¦)."""
        if not password:
            return False
        
        # ì‹¤ìš©ì  bcrypt ê²€ì¦: ê¸¸ì´ + ì ‘ë‘ì‚¬ í™•ì¸ (ë³´ì•ˆìƒ ì¶©ë¶„)
        # bcryptëŠ” ì •í™•íˆ 60ìì´ê³  $2[aby]$ë¡œ ì‹œì‘
        if len(password) != 60:
            return False
        
        # bcrypt ì ‘ë‘ì‚¬ í™•ì¸ ($2a$, $2b$, $2y$ ì§€ì›)
        if not (password.startswith('$2a$') or 
                password.startswith('$2b$') or 
                password.startswith('$2y$')):
            return False
        
        # Cost ë¶€ë¶„ í™•ì¸ (4-6ë²ˆì§¸ ë¬¸ìëŠ” ìˆ«ìì—¬ì•¼ í•¨)
        try:
            cost_part = password[4:6]
            int(cost_part)  # ìˆ«ìì¸ì§€ í™•ì¸
            return password[6] == '$'  # 7ë²ˆì§¸ ë¬¸ìëŠ” $
        except (ValueError, IndexError):
            return False
    
    @staticmethod
    def is_sha256_hash(password: str) -> bool:
        """SHA256 í•´ì‹œì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤ (Legacy ì§€ì›)."""
        if not password:
            return False
        
        # SHA256ì€ 64ìì˜ hexadecimal ë¬¸ìì—´
        return len(password) == 64 and all(c in '0123456789abcdef' for c in password.lower())
    
    @staticmethod
    def should_rehash_password(hashed_password: str) -> bool:
        """íŒ¨ìŠ¤ì›Œë“œ ì¬í•´ì‹±ì´ í•„ìš”í•œì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        if not hashed_password:
            return True
        
        # bcryptê°€ ì•„ë‹Œ ëª¨ë“  í•´ì‹œëŠ” ì¬í•´ì‹± í•„ìš”
        if not BasePostgreSQLManager.is_bcrypt_hash(hashed_password):
            return True
        
        # bcrypt costê°€ ë‚®ì€ ê²½ìš° ì¬í•´ì‹± (Enterpriseê¸‰ì€ cost 12+)
        if BCRYPT_AVAILABLE:
            try:
                # bcrypt í•´ì‹œì—ì„œ cost ì¶”ì¶œ
                cost_match = re.search(r'\$2[aby]\$(\d{2})\$', hashed_password)
                if cost_match:
                    cost = int(cost_match.group(1))
                    return cost < 12  # Enterpriseê¸‰ ë³´ì•ˆì„ ìœ„í•´ cost 12 ë¯¸ë§Œì€ ì¬í•´ì‹±
            except:
                pass
        
        return False
